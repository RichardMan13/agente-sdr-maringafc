import os
import json
from typing import Annotated, TypedDict, List, Optional
from dotenv import load_dotenv
from pydantic import BaseModel, Field

# Imports atualizados conforme requirements.txt e padr√µes LangChain 0.3+
from langchain_openai import ChatOpenAI, OpenAIEmbeddings
from langchain_community.vectorstores import SupabaseVectorStore
from supabase.client import create_client
from langchain_core.messages import BaseMessage, HumanMessage, AIMessage, SystemMessage, RemoveMessage
from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder
from langgraph.graph import StateGraph, END
from langgraph.graph.message import add_messages

load_dotenv()

# 1. Configura√ß√£o de Clientes
supabase = create_client(os.getenv("SUPABASE_URL"), os.getenv("SUPABASE_KEY"))
embeddings = OpenAIEmbeddings(model="text-embedding-3-small")
llm = ChatOpenAI(model="gpt-4o", temperature=0.7)

# 2. Configura√ß√£o do Retriever (RAG)
vector_store = SupabaseVectorStore(
    client=supabase,
    embedding=embeddings,
    table_name="conhecimento_clube",
    query_name="match_documents",
)
retriever = vector_store.as_retriever(search_kwargs={'k': 3})

# 3. Defini√ß√£o do Estado do Grafo
class AgentState(TypedDict):
    messages: Annotated[List[BaseMessage], add_messages]
    context: str
    whatsapp_id: str
    intent_is_sale: bool
    nome_torcedor: Optional[str] # Mem√≥ria persistente
    plano_interesse: Optional[str] # Mem√≥ria persistente

# --- FUN√á√ïES DE APOIO (A√á√ïES DO GRAFO) ---

def retrieve_docs(state: AgentState):
    """Busca documentos diretamente via RPC no Supabase para evitar bug de vers√£o."""
    last_message = state['messages'][-1].content
    
    # Query Rewriting: Reescreve a pergunta usando o hist√≥rico recente para dar contexto ao Vector Store
    # Evita buscas vagas como "quanto custa?" -> "quanto custa o plano Maring√° Paix√£o?"
    historico_recente = parse_messages(state['messages'][-4:]) # Pega as √∫ltimas 4 mensagens
    prompt_rewrite = f"""Reescreva a √∫ltima pergunta do usu√°rio para que ela seja independente e completa, baseada no hist√≥rico.
    Hist√≥rico: {historico_recente}
    Pergunta original: {last_message}
    Responda APENAS a pergunta reescrita."""
    
    try:
        busca_otimizada = llm.invoke(prompt_rewrite).content
        print(f"üîÑ Busca Original: '{last_message}' | Busca Otimizada: '{busca_otimizada}'")
    except:
        busca_otimizada = last_message
    
    # 1. Gera o embedding da pergunta otimizada
    query_embedding = embeddings.embed_query(busca_otimizada)
    
    # 2. Chama a fun√ß√£o RPC 'match_documents' que criamos no SQL Editor
    # Isso pula o erro do 'SyncRPCFilterRequestBuilder'
    rpc_res = supabase.rpc("match_documents", {
        "query_embedding": query_embedding,
        "match_threshold": 0.5, # Ajuste conforme necessidade
        "match_count": 3
    }).execute()
    
    # 3. Processa os resultados
    if not rpc_res.data:
        return {"context": "Nenhuma informa√ß√£o encontrada no banco."}
        
    context = "\n\n".join([item['conteudo'] for item in rpc_res.data])

    return {"context": context}

def summarize_conversation(state: AgentState):
    """Resume a conversa se houver muitas mensagens para economizar tokens."""
    
    # Mant√©m as √∫ltimas 4 mensagens (aprox) + a System Message inicial (se houver)
    # O resto ser√° resumido. 
    stored_messages = state['messages']
    
    # Se tiver poucas mensagens, n√£o faz nada
    if len(stored_messages) <= 6:
        return {}
    
    # Identifica o que ser√° resumido (tudo exceto as √∫ltimas 4)
    # Assume que a primeira mensagem pode ser um SystemMessage fixo ou n√£o.
    # Vamos resumir tudo exceto as 4 √∫ltimas para garantir contexto recente.
    to_summarize = stored_messages[:-4]
    
    if not to_summarize:
        return {}
        
    # Gera o resumo usando a LLM
    # Cria um prompt espec√≠fico para a sumariza√ß√£o
    summary_message = parse_messages(to_summarize)
    prompt = f"Resuma a seguinte conversa entre um Torcedor e o Dog√£o (SDR do Maring√° FC). Mantenha detalhes sobre o Torcedor (nome, plano de interesse, d√∫vidas). \n\nConversa:\n{summary_message}"
    
    response = llm.invoke(prompt)
    summary = response.content
    
    # Cria a lista de remo√ß√£o (apaga as mensagens antigas do hist√≥rico via ID)
    delete_messages = [RemoveMessage(id=m.id) for m in to_summarize]
    
    # Cria a mensagem de resumo para injetar no hist√≥rico como uma SystemMessage
    # Isso garante que o modelo saiba o que aconteceu antes
    summary_msg = SystemMessage(content=f"RESUMO DA CONVERSA ANTERIOR: {summary}")
    
    print(f"üìâ Resumindo {len(to_summarize)} mensagens antigas...")
    
    # Retorna as remo√ß√µes E a nova mensagem de resumo
    return {"messages": delete_messages + [summary_msg]}

def parse_messages(messages):
    """Helper para formatar mensagens para o prompt de resumo"""
    return "\\n".join([f"{m.type}: {m.content}" for m in messages])

class LeadInfo(BaseModel):
    venda: bool = Field(description="Indica se o usu√°rio demonstrou interesse claro em comprar algo ou saber sobre planos")
    nome: Optional[str] = Field(default=None, description="Nome do torcedor, se informado")
    plano: Optional[str] = Field(default=None, description="Plano de interesse, se informado")

def call_model(state: AgentState):
    """Gera a resposta da Persona Dog√£o."""
    prompt = ChatPromptTemplate.from_messages([
        ("system", """Voc√™ √© o "Dog√£o", o SDR oficial do Maring√° FC. 
        Seja extrovertido, apaixonado e persuasivo. Use o CONTEXTO para responder.
        Se houver interesse em planos, capture Nome e WhatsApp.
        
        CONTEXTO:
        {context}"""),
        MessagesPlaceholder(variable_name="messages"),
    ])
    
    chain = prompt | llm
    
    # A otimiza√ß√£o de mensagens agora √© feita pelo n√≥ 'summarizer',
    # ent√£o passamos todas as mensagens dispon√≠veis no estado (que j√° estar√£o resumidas/cortadas)
    response = chain.invoke({"messages": state['messages'], "context": state['context']})
    return {"messages": [response]}

def classify_and_track(state: AgentState):
    """Analisa inten√ß√£o e salva lead na tabela leads_sdr se necess√°rio."""
    
    # Verifica√ß√£o de seguran√ßa: se houver menos de 2 mensagens, n√£o h√° o que comparar
    if len(state['messages']) < 2:
        return {"intent_is_sale": False}
    # Valida√ß√£o de inten√ß√£o usando Structured Output (Pydantic)
    # Analisa TODO o hist√≥rico de mensagens para n√£o perder informa√ß√µes (ex: nome dito anteriormente)
    historico_conversa = parse_messages(state['messages'])
    
    prompt_analise = f"""Analise o hist√≥rico da conversa abaixo e extraia inten√ß√µes de venda.
    
    Dados Atuais no Sistema:
    - Nome: {state.get('nome_torcedor') or 'N√£o informado'}
    - Plano: {state.get('plano_interesse') or 'N√£o informado'}
    
    Instru√ß√µes:
    1. Se o "Nome" j√° estiver preenchido, S√ì extraia um novo nome se o usu√°rio corrigir explicitamente (ex: "N√£o √© Jo√£o, √© Pedro").
    2. Se o "Plano" mudar, atualize para o novo.
    
    Hist√≥rico:
    {historico_conversa}
    """

    try:
        # Usa with_structured_output para garantir JSON v√°lido (Extra√ß√£o de JSON Inst√°vel)
        structured_llm = llm.with_structured_output(LeadInfo)
        lead_data = structured_llm.invoke(prompt_analise)
        
        # L√≥gica de Persist√™ncia com Resolu√ß√£o de Conflitos
        updates = {}
        
        # S√≥ atualiza o nome se ainda n√£o tiver um, ou se a LLM indicar troca expl√≠cita (pode ser refinado no prompt)
        current_nome = state.get('nome_torcedor')
        new_nome = lead_data.nome
        
        if new_nome and new_nome != "Torcedor Interessado":
             # Se j√° temos um nome e o novo √© diferente, s√≥ troca se parecer uma corre√ß√£o (Regra simples: sempre confia no √∫ltimo por enquanto, mas loga)
            if current_nome and current_nome != new_nome:
                 print(f"‚ö†Ô∏è Atualizando Nome: {current_nome} -> {new_nome}")
            updates['nome_torcedor'] = new_nome
            
        # Mesmo para plano
        current_plano = state.get('plano_interesse')
        new_plano = lead_data.plano
        if new_plano and new_plano != "A definir":
            updates['plano_interesse'] = new_plano
            
        # Define os valores finais para o UPSERT (prioriza o estado atualizado)
        nome_final = updates.get('nome_torcedor') or current_nome or "Torcedor Interessado"
        plano_final = updates.get('plano_interesse') or current_plano or "A definir"
        
        if lead_data.venda:
            supabase.table("leads_sdr").upsert({
                "whatsapp_id": state['whatsapp_id'],
                "nome_torcedor": nome_final,
                "plano_interesse": plano_final,
                "convertido": False
            }, on_conflict="whatsapp_id").execute()
            print(f"üéØ Lead registrado: {nome_final}")
            
        # Retorna atualiza√ß√µes para o estado (se houver) + inten√ß√£o
        return {**updates, "intent_is_sale": True}
        
    except Exception as e:
        print(f"‚ö†Ô∏è Erro no tracking: {e}")
        return {"intent_is_sale": False}

# 4. Constru√ß√£o do Fluxo (LangGraph)
workflow = StateGraph(AgentState)

# L√≥gica condicional para definir se precisa resumir
def should_summarize(state: AgentState):
    """Retorna o pr√≥ximo n√≥ baseado no tamanho do hist√≥rico."""
    messages = state['messages']
    
    # Se tiver mais de 6 mensagens, vai para o summarizer
    if len(messages) > 6:
        return "summarizer"
    
    # Caso contr√°rio, segue o fluxo normal
    return "dogao_chat"

workflow.add_node("retriever", retrieve_docs)
workflow.add_node("summarizer", summarize_conversation)
workflow.add_node("dogao_chat", call_model)
workflow.add_node("lead_tracker", classify_and_track)

workflow.set_entry_point("retriever")

# Arestas condicionais
workflow.add_conditional_edges(
    "retriever",
    should_summarize,
    {
        "summarizer": "summarizer",
        "dogao_chat": "dogao_chat"
    }
)

# Aresta normal para voltar do summarizer para o chat
workflow.add_edge("summarizer", "dogao_chat")
workflow.add_edge("dogao_chat", "lead_tracker")
workflow.add_edge("lead_tracker", END)

# Compila o Agente
dogao_agent = workflow.compile()